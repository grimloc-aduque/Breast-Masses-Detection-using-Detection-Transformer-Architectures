{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from detr_config import Config\n",
    "from detr_dataset import get_dataset, get_dataloader\n",
    "from detr_trainer import get_trainer\n",
    "from detr_evaluation import load_best_model, get_metrics\n",
    "from detr_model import DETRModel\n",
    "from transformers import (DeformableDetrConfig,\n",
    "                          DeformableDetrForObjectDetection,\n",
    "                          DeformableDetrImageProcessor, DetrConfig,\n",
    "                          DetrForObjectDetection, DetrImageProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- MODEL --------\n",
      " balloon_model=DETR_backbone=resnet50_queries=100_dmodel=256_layers=6 \n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:197: UserWarning: Attribute 'detr_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['detr_model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | detr_model | DetrForObjectDetection | 41.5 M\n",
      "------------------------------------------------------\n",
      "41.3 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.5 M    Total params\n",
      "166.007   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x000002B48017D240>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5f6ce93a3a4d2791b5fedd7462bf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:490: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 5. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a4afc349ce4e1da3f6a3a8a2b67acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# HyperParameters\n",
    "\n",
    "hyperparameters = Config.HYPERPARAMS\n",
    "\n",
    "hyperparameters = [\n",
    "    ('DETR', 'resnet50', 100, 256, 6),\n",
    "    # ('D-DETR', 'resnet50', 300, 256, 6),\n",
    "]\n",
    "\n",
    "# Hyperparameter Search\n",
    "\n",
    "for architecture, backbone, num_queries, d_model, transformer_layers in hyperparameters:\n",
    "    \n",
    "    if architecture == 'DETR':\n",
    "        IMG_PROCESSOR_CLASS = DetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DetrConfig\n",
    "        DETR_CLASS = DetrForObjectDetection\n",
    "    else:\n",
    "        IMG_PROCESSOR_CLASS = DeformableDetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DeformableDetrConfig\n",
    "        DETR_CLASS = DeformableDetrForObjectDetection    \n",
    "    \n",
    "    # Model Configuration\n",
    "\n",
    "    config = DETR_CONFIG_CLASS(\n",
    "        num_labels = Config.NUM_CLASSES,\n",
    "        id2label = {0:'Mass'}, \n",
    "        label2id = {'Mass': 0},\n",
    "        num_queries = num_queries,\n",
    "        d_model = d_model,\n",
    "        encoder_layers = transformer_layers,\n",
    "        decoder_layers = transformer_layers,\n",
    "        backbone=backbone\n",
    "    )\n",
    "    \n",
    "    # Model Directory\n",
    "\n",
    "    model_name = [\n",
    "        'balloon',\n",
    "        f'model={architecture}',\n",
    "        f'backbone={backbone.split(\".\")[0]}',\n",
    "        f'queries={num_queries}',\n",
    "        f'dmodel={d_model}',\n",
    "        f'layers={transformer_layers}'\n",
    "    ]\n",
    "    \n",
    "    model_name = '_'.join(model_name)\n",
    "    model_dir = os.path.join(Config.LOGS_DIR, model_name)\n",
    "    # if os.path.exists(model_dir):\n",
    "    #     shutil.rmtree(model_dir)\n",
    "    print('\\n-------- MODEL --------\\n', model_name,\n",
    "          '\\n-----------------------\\n')\n",
    "    \n",
    "    \n",
    "    # K-fold Cross Validation \n",
    "    \n",
    "    metrics_by_fold = []\n",
    "    index = []\n",
    "\n",
    "    for fold in range(1,11):\n",
    "        \n",
    "        # Model\n",
    "        \n",
    "        image_processor = IMG_PROCESSOR_CLASS()        \n",
    "        detr_model = DETR_CLASS(config=config)\n",
    "        model = DETRModel(detr_model=detr_model)\n",
    "        \n",
    "        # Datasets\n",
    "        \n",
    "        fold_name = f'fold_{fold}'\n",
    "        dataset_dir = os.path.join(Config.DATASET, fold_name)\n",
    "        dataset_dir = './balloon/'\n",
    "        \n",
    "        train_dir = os.path.join(dataset_dir, 'train')\n",
    "        train_dataset = get_dataset(train_dir, image_processor)\n",
    "        train_loader = get_dataloader(train_dataset, image_processor)\n",
    "        \n",
    "        valid_dir = os.path.join(dataset_dir, 'valid')\n",
    "        valid_dataset = get_dataset(valid_dir, image_processor)\n",
    "        valid_loader = get_dataloader(valid_dataset, image_processor)\n",
    "\n",
    "        # Training\n",
    "        \n",
    "        version = os.path.join(model_name, fold_name)\n",
    "        trainer = get_trainer(version)\n",
    "        trainer.fit(model, train_dataloaders=train_loader,\n",
    "                    val_dataloaders=valid_loader)\n",
    "        \n",
    "        # Validation\n",
    "\n",
    "        model = load_best_model(version)\n",
    "        metrics_dict = get_metrics(model, valid_dataset, image_processor, threshold=0.001)\n",
    "        metrics_by_fold.append(metrics_dict)\n",
    "        index.append(fold_name)\n",
    "        \n",
    "        if fold != 1:\n",
    "            print(\"Cleaning Checkpoints\")\n",
    "            # shutil.rmtree(checkpoints_dir)\n",
    "\n",
    "        break # Fold\n",
    "    \n",
    "    \n",
    "    # Aggregate Metrics\n",
    "    \n",
    "    metrics_by_fold = pd.DataFrame(metrics_by_fold, index=index)\n",
    "    metrics_by_fold.loc['mean'] = metrics_by_fold.mean()\n",
    "    metrics_path = os.path.join(Config.LOGS_DIR, model_name, Config.METRICS_FILE)\n",
    "    metrics_by_fold.to_csv(metrics_path)\n",
    "    \n",
    "    break # Hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
