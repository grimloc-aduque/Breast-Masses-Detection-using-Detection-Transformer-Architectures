{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from coco_eval import CocoEvaluator\n",
    "from detr_config import Config\n",
    "from detr_dataset import InBreastDataset, collate_fn, detr_processor\n",
    "from detr_detection import prepare_for_coco_detection\n",
    "from detr_model import DETRModel\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DetrConfig, DetrForObjectDetection\n",
    "\n",
    "STDOUT = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Num Queries, Dim model, Enc-Dec Layers):  (25, 64, 2)\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.decoder.layers.2.final_layer_norm.weight', 'model.backbone.conv_encoder.model.layer1.0.bn2.running_mean', 'model.encoder.layers.4.self_attn.out_proj.weight', 'model.backbone.conv_encoder.model.layer3.1.bn1.bias', 'model.decoder.layers.3.encoder_attn.out_proj.weight', 'model.backbone.conv_encoder.model.layer4.2.conv1.weight', 'model.encoder.layers.5.self_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer1.2.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.0.bn1.running_mean', 'model.encoder.layers.4.self_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer3.1.bn3.running_mean', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer2.0.bn2.weight', 'model.backbone.conv_encoder.model.layer2.3.bn3.running_mean', 'model.backbone.conv_encoder.model.layer3.0.downsample.0.weight', 'model.encoder.layers.4.fc1.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer2.1.conv2.weight', 'model.decoder.layers.4.encoder_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer2.2.bn3.running_var', 'model.backbone.conv_encoder.model.layer1.1.conv1.weight', 'model.encoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer3.2.bn2.bias', 'model.backbone.conv_encoder.model.layer4.1.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.3.conv1.weight', 'model.encoder.layers.3.fc2.weight', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer3.1.bn3.bias', 'model.backbone.conv_encoder.model.layer1.2.bn2.running_var', 'model.backbone.conv_encoder.model.layer3.2.bn1.weight', 'model.backbone.conv_encoder.model.layer4.1.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.2.bn1.weight', 'model.backbone.conv_encoder.model.layer3.0.bn3.weight', 'model.backbone.conv_encoder.model.layer3.5.bn3.bias', 'model.backbone.conv_encoder.model.layer2.2.bn2.weight', 'model.encoder.layers.4.self_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.weight', 'model.backbone.conv_encoder.model.layer3.1.bn2.running_mean', 'model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.backbone.conv_encoder.model.layer4.1.bn3.running_mean', 'model.encoder.layers.2.fc1.weight', 'model.backbone.conv_encoder.model.layer4.2.bn3.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer3.5.conv3.weight', 'model.decoder.layers.2.encoder_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer4.2.conv3.weight', 'model.backbone.conv_encoder.model.layer4.1.bn2.running_var', 'model.encoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer3.0.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.2.bn1.bias', 'model.decoder.layers.5.encoder_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer3.4.bn2.weight', 'model.encoder.layers.4.self_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer1.0.bn1.running_var', 'model.encoder.layers.4.fc1.bias', 'model.decoder.layers.3.encoder_attn_layer_norm.weight', 'model.backbone.conv_encoder.model.layer1.0.conv3.weight', 'model.backbone.conv_encoder.model.layer3.5.bn1.running_var', 'model.backbone.conv_encoder.model.layer1.0.bn1.bias', 'model.encoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.bias', 'model.backbone.conv_encoder.model.layer3.4.conv3.weight', 'model.backbone.conv_encoder.model.layer2.2.bn3.weight', 'model.backbone.conv_encoder.model.layer3.3.conv3.weight', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.5.final_layer_norm.bias', 'model.backbone.conv_encoder.model.layer4.1.bn1.running_var', 'model.backbone.conv_encoder.model.layer2.3.conv3.weight', 'model.backbone.conv_encoder.model.layer1.1.bn3.running_var', 'model.backbone.conv_encoder.model.layer1.1.bn2.weight', 'model.backbone.conv_encoder.model.layer3.5.bn1.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.encoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.2.encoder_attn.k_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.bias', 'model.decoder.layers.3.encoder_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer2.1.bn3.running_mean', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.running_var', 'model.decoder.layers.4.encoder_attn.k_proj.bias', 'model.backbone.conv_encoder.model.layer2.0.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.0.bn1.running_var', 'model.decoder.layers.3.encoder_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer1.0.bn2.bias', 'model.decoder.layers.2.encoder_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer4.0.bn2.weight', 'model.backbone.conv_encoder.model.layer3.0.bn1.weight', 'model.decoder.layers.2.encoder_attn_layer_norm.weight', 'model.encoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.4.fc1.weight', 'model.encoder.layers.4.fc2.weight', 'model.backbone.conv_encoder.model.layer1.2.conv2.weight', 'model.backbone.conv_encoder.model.layer3.5.bn1.running_mean', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer4.0.bn2.running_var', 'model.backbone.conv_encoder.model.layer2.1.bn2.bias', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.bias', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.encoder.layers.5.fc2.bias', 'model.backbone.conv_encoder.model.layer3.0.conv1.weight', 'model.backbone.conv_encoder.model.layer1.2.bn2.bias', 'model.backbone.conv_encoder.model.layer3.5.bn2.running_mean', 'model.decoder.layers.4.encoder_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer4.0.bn3.weight', 'model.backbone.conv_encoder.model.layer2.0.bn2.running_mean', 'model.backbone.conv_encoder.model.layer3.0.bn2.bias', 'model.backbone.conv_encoder.model.layer2.2.bn2.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer3.1.conv3.weight', 'model.decoder.layers.5.fc2.bias', 'model.encoder.layers.3.self_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer1.1.conv2.weight', 'model.backbone.conv_encoder.model.layer2.3.bn2.running_mean', 'model.backbone.conv_encoder.model.layer3.5.bn1.weight', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.2.encoder_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer3.2.bn3.running_mean', 'model.backbone.conv_encoder.model.layer1.2.bn1.weight', 'model.backbone.conv_encoder.model.layer2.0.bn1.bias', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.weight', 'model.encoder.layers.5.fc2.weight', 'model.encoder.layers.4.fc2.bias', 'model.backbone.conv_encoder.model.layer3.3.bn1.running_var', 'model.backbone.conv_encoder.model.layer2.2.bn3.running_mean', 'model.backbone.conv_encoder.model.layer3.0.bn2.running_var', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer4.0.bn2.bias', 'model.backbone.conv_encoder.model.layer2.1.bn2.running_var', 'model.backbone.conv_encoder.model.layer4.2.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.3.bn1.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer4.0.bn2.running_mean', 'model.backbone.conv_encoder.model.layer2.1.bn2.running_mean', 'model.decoder.layers.5.encoder_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer3.0.bn2.weight', 'model.backbone.conv_encoder.model.layer4.1.bn3.weight', 'model.backbone.conv_encoder.model.layer3.5.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.1.bn2.weight', 'model.backbone.conv_encoder.model.layer4.0.conv2.weight', 'model.decoder.layers.4.encoder_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer1.2.bn2.running_mean', 'model.backbone.conv_encoder.model.layer2.1.bn1.running_var', 'model.backbone.conv_encoder.model.layer3.4.conv2.weight', 'model.backbone.conv_encoder.model.layer4.2.bn3.running_mean', 'model.backbone.conv_encoder.model.layer3.5.bn2.weight', 'model.backbone.conv_encoder.model.layer4.0.bn3.running_mean', 'model.backbone.conv_encoder.model.layer3.5.bn2.bias', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.running_mean', 'model.backbone.conv_encoder.model.layer1.1.bn3.bias', 'model.encoder.layers.5.self_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer2.1.bn3.running_var', 'model.backbone.conv_encoder.model.layer2.3.bn2.weight', 'model.encoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.2.encoder_attn_layer_norm.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.encoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.4.encoder_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer2.3.bn1.bias', 'model.encoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.encoder.layers.3.self_attn_layer_norm.weight', 'model.backbone.conv_encoder.model.layer1.0.bn2.weight', 'model.encoder.layers.5.self_attn_layer_norm.weight', 'model.backbone.conv_encoder.model.layer2.2.bn1.weight', 'model.backbone.conv_encoder.model.layer3.2.bn2.running_mean', 'model.backbone.conv_encoder.model.layer2.1.bn3.weight', 'model.backbone.conv_encoder.model.layer3.4.bn1.bias', 'model.backbone.conv_encoder.model.layer3.2.bn2.running_var', 'model.encoder.layers.5.self_attn.out_proj.weight', 'model.backbone.conv_encoder.model.layer3.2.conv2.weight', 'model.backbone.conv_encoder.model.layer3.1.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.3.bn3.bias', 'model.backbone.conv_encoder.model.layer2.1.bn3.bias', 'model.encoder.layers.4.self_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer3.3.bn1.bias', 'model.backbone.conv_encoder.model.layer2.0.bn1.running_mean', 'model.backbone.conv_encoder.model.layer2.0.bn3.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer1.2.bn3.running_var', 'model.decoder.layers.5.encoder_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer3.0.bn3.running_var', 'model.encoder.layers.4.self_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.3.bn1.running_var', 'model.decoder.layers.2.encoder_attn.q_proj.bias', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.backbone.conv_encoder.model.layer3.3.bn2.running_mean', 'model.backbone.conv_encoder.model.layer1.1.bn3.weight', 'model.backbone.conv_encoder.model.layer3.3.bn3.weight', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.3.fc1.weight', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.encoder.layers.5.final_layer_norm.bias', 'model.encoder.layers.4.self_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer3.4.bn1.running_var', 'model.decoder.layers.3.encoder_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer4.1.bn2.weight', 'model.backbone.conv_encoder.model.layer2.3.bn2.bias', 'model.backbone.conv_encoder.model.layer3.4.bn3.running_var', 'model.encoder.layers.5.fc1.bias', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.encoder.layers.2.self_attn.out_proj.weight', 'model.backbone.conv_encoder.model.layer3.0.bn2.running_mean', 'model.encoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.encoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer2.3.conv1.weight', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.3.encoder_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.encoder.layers.2.fc2.bias', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer2.1.conv1.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer3.3.bn2.weight', 'model.decoder.layers.3.fc2.weight', 'model.backbone.conv_encoder.model.layer2.2.bn1.running_mean', 'model.backbone.conv_encoder.model.layer2.1.conv3.weight', 'model.backbone.conv_encoder.model.layer3.4.bn2.bias', 'model.encoder.layers.3.fc1.weight', 'model.backbone.conv_encoder.model.layer2.3.conv2.weight', 'model.backbone.conv_encoder.model.layer1.2.bn2.weight', 'model.backbone.conv_encoder.model.layer1.0.bn3.weight', 'model.backbone.conv_encoder.model.layer3.4.bn1.weight', 'model.backbone.conv_encoder.model.layer4.2.bn3.weight', 'model.backbone.conv_encoder.model.layer3.3.bn2.running_var', 'model.backbone.conv_encoder.model.layer1.0.bn3.running_var', 'model.encoder.layers.3.fc1.bias', 'model.backbone.conv_encoder.model.layer3.0.bn1.bias', 'model.decoder.layers.3.encoder_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer2.2.bn1.bias', 'model.backbone.conv_encoder.model.layer4.1.bn2.bias', 'model.backbone.conv_encoder.model.conv1.weight', 'model.backbone.conv_encoder.model.layer2.3.bn3.weight', 'model.backbone.conv_encoder.model.layer1.1.bn1.bias', 'model.encoder.layers.3.self_attn.out_proj.weight', 'model.backbone.conv_encoder.model.layer4.2.bn2.bias', 'model.backbone.conv_encoder.model.layer1.0.bn3.bias', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.5.encoder_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer4.1.conv2.weight', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.running_var', 'model.backbone.conv_encoder.model.layer4.2.conv2.weight', 'model.decoder.layers.5.fc1.bias', 'model.backbone.conv_encoder.model.layer1.1.bn1.running_var', 'model.backbone.conv_encoder.model.layer1.2.bn1.bias', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.running_mean', 'model.backbone.conv_encoder.model.layer3.2.conv3.weight', 'model.backbone.conv_encoder.model.layer1.1.bn2.running_var', 'model.backbone.conv_encoder.model.layer3.1.bn2.bias', 'model.encoder.layers.5.self_attn.k_proj.bias', 'model.backbone.conv_encoder.model.layer4.0.conv1.weight', 'model.backbone.conv_encoder.model.layer3.2.bn3.running_var', 'model.backbone.conv_encoder.model.layer1.1.bn2.bias', 'model.backbone.conv_encoder.model.layer1.0.bn3.running_mean', 'model.encoder.layers.3.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer2.3.bn3.bias', 'model.backbone.conv_encoder.model.layer3.0.conv2.weight', 'model.backbone.conv_encoder.model.layer1.1.bn2.running_mean', 'model.backbone.conv_encoder.model.layer2.2.bn3.bias', 'model.backbone.conv_encoder.model.layer1.1.bn3.running_mean', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.bn1.weight', 'model.backbone.conv_encoder.model.layer4.1.bn1.bias', 'model.decoder.layers.4.encoder_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.backbone.conv_encoder.model.layer2.0.bn3.bias', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.bias', 'model.backbone.conv_encoder.model.layer3.4.bn3.weight', 'model.decoder.layers.2.encoder_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer1.0.bn2.running_var', 'model.backbone.conv_encoder.model.layer2.0.conv1.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.running_var', 'model.backbone.conv_encoder.model.layer4.0.bn1.running_var', 'model.backbone.conv_encoder.model.layer2.1.bn1.weight', 'model.backbone.conv_encoder.model.layer3.5.conv2.weight', 'model.backbone.conv_encoder.model.layer2.3.bn1.weight', 'model.decoder.layers.2.fc2.weight', 'model.backbone.conv_encoder.model.layer2.1.bn1.running_mean', 'model.encoder.layers.4.self_attn.k_proj.bias', 'model.backbone.conv_encoder.model.layer1.2.bn3.weight', 'model.encoder.layers.3.final_layer_norm.bias', 'model.backbone.conv_encoder.model.layer2.3.bn1.running_mean', 'model.backbone.conv_encoder.model.layer3.5.bn3.running_mean', 'model.backbone.conv_encoder.model.layer4.2.bn1.running_var', 'model.encoder.layers.2.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer4.0.bn1.bias', 'model.backbone.conv_encoder.model.layer3.1.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.1.conv3.weight', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.weight', 'model.backbone.conv_encoder.model.layer2.3.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.2.bn3.bias', 'model.backbone.conv_encoder.model.layer2.0.bn2.running_var', 'model.encoder.layers.3.self_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer3.0.bn3.running_mean', 'model.encoder.layers.5.fc1.weight', 'model.backbone.conv_encoder.model.layer3.1.conv2.weight', 'model.backbone.conv_encoder.model.layer3.3.bn3.running_mean', 'model.backbone.conv_encoder.model.layer3.2.bn3.weight', 'model.decoder.layers.4.encoder_attn_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.5.encoder_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer3.5.bn3.weight', 'model.backbone.conv_encoder.model.layer2.0.bn1.weight', 'model.encoder.layers.4.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer2.1.bn2.weight', 'model.backbone.conv_encoder.model.layer1.0.bn1.running_mean', 'model.backbone.conv_encoder.model.layer2.2.bn2.running_var', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.backbone.conv_encoder.model.layer4.1.bn3.bias', 'model.decoder.layers.4.encoder_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer1.0.conv1.weight', 'model.decoder.layers.5.fc2.weight', 'model.backbone.conv_encoder.model.layer2.0.conv2.weight', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.encoder.layers.2.self_attn.q_proj.weight', 'model.backbone.conv_encoder.model.layer2.0.bn2.bias', 'model.backbone.conv_encoder.model.layer3.3.conv2.weight', 'model.backbone.conv_encoder.model.layer3.3.bn2.bias', 'model.decoder.layers.2.fc2.bias', 'model.backbone.conv_encoder.model.layer3.1.bn3.weight', 'model.backbone.conv_encoder.model.layer4.0.conv3.weight', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.running_mean', 'model.backbone.conv_encoder.model.layer4.1.bn2.running_mean', 'model.encoder.layers.2.self_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer4.0.bn1.weight', 'model.decoder.layers.2.encoder_attn.out_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer3.1.bn1.running_var', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.running_mean', 'model.backbone.conv_encoder.model.layer3.5.conv1.weight', 'model.decoder.layers.4.encoder_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer3.0.bn3.bias', 'model.backbone.conv_encoder.model.layer4.2.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.1.bn1.weight', 'model.backbone.conv_encoder.model.layer3.4.bn2.running_mean', 'model.backbone.conv_encoder.model.layer2.0.bn3.running_mean', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.bias', 'model.backbone.conv_encoder.model.layer4.0.downsample.0.weight', 'model.encoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.3.encoder_attn.k_proj.bias', 'model.encoder.layers.3.self_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer3.2.bn1.bias', 'model.encoder.layers.2.self_attn.v_proj.bias', 'model.backbone.conv_encoder.model.layer3.2.bn2.weight', 'model.encoder.layers.5.self_attn_layer_norm.bias', 'model.backbone.conv_encoder.model.layer1.2.bn1.running_var', 'model.encoder.layers.2.fc1.bias', 'model.backbone.conv_encoder.model.layer3.2.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.2.bn2.weight', 'model.encoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.5.encoder_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer3.4.conv1.weight', 'model.backbone.conv_encoder.model.layer2.2.conv2.weight', 'model.encoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.backbone.conv_encoder.model.layer4.2.bn2.running_mean', 'model.encoder.layers.5.self_attn.q_proj.weight', 'model.encoder.layers.3.self_attn.k_proj.bias', 'model.encoder.layers.2.self_attn_layer_norm.weight', 'model.backbone.conv_encoder.model.layer2.2.bn1.running_var', 'model.backbone.conv_encoder.model.layer1.0.downsample.0.weight', 'model.backbone.conv_encoder.model.layer2.2.conv3.weight', 'model.backbone.conv_encoder.model.layer1.2.bn3.bias', 'model.backbone.conv_encoder.model.layer2.2.conv1.weight', 'model.backbone.conv_encoder.model.layer1.1.bn1.weight', 'model.backbone.conv_encoder.model.layer4.1.conv1.weight', 'model.backbone.conv_encoder.model.layer2.3.bn2.running_var', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.encoder.layers.3.fc2.bias', 'model.encoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.5.final_layer_norm.weight', 'model.backbone.conv_encoder.model.layer1.1.bn1.running_mean', 'model.backbone.conv_encoder.model.layer3.0.conv3.weight', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.weight', 'model.decoder.layers.4.encoder_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer1.2.conv3.weight', 'model.decoder.layers.2.encoder_attn.k_proj.weight', 'model.encoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.2.fc1.weight', 'model.backbone.conv_encoder.model.layer4.0.bn3.bias', 'model.backbone.conv_encoder.model.layer1.0.conv2.weight', 'model.decoder.layers.4.fc1.bias', 'model.backbone.conv_encoder.model.layer3.2.conv1.weight', 'model.backbone.conv_encoder.model.layer3.5.bn2.running_var', 'model.backbone.conv_encoder.model.layer1.2.conv1.weight', 'model.backbone.conv_encoder.model.layer3.1.conv1.weight', 'model.backbone.conv_encoder.model.layer3.3.bn1.running_mean', 'model.backbone.conv_encoder.model.layer4.2.bn2.running_var', 'model.backbone.conv_encoder.model.layer3.4.bn2.running_var', 'model.decoder.layers.5.encoder_attn.k_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.backbone.conv_encoder.model.layer1.2.bn3.running_mean', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.backbone.conv_encoder.model.layer3.1.bn1.weight', 'model.backbone.conv_encoder.model.layer3.4.bn3.running_mean', 'model.backbone.conv_encoder.model.layer2.0.downsample.0.weight', 'model.decoder.layers.5.encoder_attn.out_proj.bias', 'model.backbone.conv_encoder.model.layer2.1.bn1.bias', 'model.decoder.layers.4.final_layer_norm.weight', 'model.backbone.conv_encoder.model.layer1.1.conv3.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.backbone.conv_encoder.model.layer3.3.bn3.running_var', 'model.backbone.conv_encoder.model.layer3.4.bn3.bias', 'model.encoder.layers.2.fc2.weight', 'model.backbone.conv_encoder.model.layer3.1.bn2.running_var', 'model.encoder.layers.5.self_attn.q_proj.bias', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.running_var', 'model.backbone.conv_encoder.model.layer3.2.bn1.running_var', 'model.backbone.conv_encoder.model.layer2.2.bn2.running_mean', 'model.encoder.layers.5.self_attn.v_proj.weight', 'model.backbone.conv_encoder.model.layer4.0.bn3.running_var', 'model.decoder.layers.2.fc1.bias', 'model.backbone.conv_encoder.model.layer3.4.bn1.running_mean', 'model.backbone.conv_encoder.model.layer2.0.conv3.weight', 'model.backbone.conv_encoder.model.layer2.0.bn1.running_var']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized: ['model.backbone.conv_encoder.model.blocks.5.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.0.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.2.1.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.2.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.2.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.4.1.bn3.weight', 'model.backbone.conv_encoder.model.blocks.3.0.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.0.0.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.0.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.3.2.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.1.1.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn3.bias', 'model.backbone.conv_encoder.model.blocks.5.1.bn1.weight', 'model.backbone.conv_encoder.model.blocks.4.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.1.1.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.6.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.5.2.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.3.1.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.5.3.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.2.1.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.3.2.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.4.2.bn3.bias', 'model.backbone.conv_encoder.model.blocks.3.1.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.3.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.3.2.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.2.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.4.1.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn2.bias', 'model.backbone.conv_encoder.model.blocks.1.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.4.2.bn2.weight', 'model.backbone.conv_encoder.model.blocks.4.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.6.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.3.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.1.0.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.3.2.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.1.1.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.4.1.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.1.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.1.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.2.0.bn3.weight', 'model.backbone.conv_encoder.model.blocks.2.1.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.5.0.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.6.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.5.1.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.1.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.4.1.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.0.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.1.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.3.1.bn3.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn2.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn1.bias', 'model.backbone.conv_encoder.model.blocks.5.3.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.3.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.3.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.3.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.6.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.0.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn2.weight', 'model.backbone.conv_encoder.model.blocks.5.1.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.2.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.3.1.bn1.bias', 'model.backbone.conv_encoder.model.blocks.5.2.bn2.bias', 'model.backbone.conv_encoder.model.blocks.6.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.4.2.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.4.2.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.3.2.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.4.1.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.5.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.3.bn3.bias', 'model.backbone.conv_encoder.model.blocks.4.1.bn2.bias', 'model.backbone.conv_encoder.model.blocks.4.2.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.2.1.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.6.0.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.5.2.bn2.weight', 'model.backbone.conv_encoder.model.blocks.1.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.2.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.3.1.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.5.3.bn2.bias', 'model.backbone.conv_encoder.model.blocks.6.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.3.1.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.5.2.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.2.1.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.3.0.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.5.0.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.5.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.2.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.3.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.2.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.2.1.bn2.weight', 'model.backbone.conv_encoder.model.blocks.2.0.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.3.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.5.2.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.5.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.1.1.bn1.bias', 'model.backbone.conv_encoder.model.blocks.2.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.5.2.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.2.1.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.3.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.0.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.1.1.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.5.1.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.5.2.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.3.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.6.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.1.0.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.2.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.0.bn3.weight', 'model.backbone.conv_encoder.model.blocks.2.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.4.2.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.1.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.3.1.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.2.1.bn1.bias', 'model.backbone.conv_encoder.model.blocks.3.1.bn2.weight', 'model.backbone.conv_encoder.model.blocks.0.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.1.1.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.5.0.bn3.bias', 'model.backbone.conv_encoder.model.blocks.2.1.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.1.1.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.4.2.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.5.2.bn1.bias', 'model.backbone.conv_encoder.model.blocks.1.0.bn3.bias', 'model.backbone.conv_encoder.model.blocks.2.1.bn3.weight', 'model.backbone.conv_encoder.model.blocks.6.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.2.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.3.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.1.1.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.4.2.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.5.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.4.1.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.4.2.bn2.bias', 'model.backbone.conv_encoder.model.blocks.1.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.3.1.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.0.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.4.1.bn2.weight', 'model.backbone.conv_encoder.model.blocks.5.3.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.4.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.1.1.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.2.1.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.6.0.bn3.bias', 'model.backbone.conv_encoder.model.blocks.5.1.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.4.2.bn1.weight', 'model.backbone.conv_encoder.model.blocks.3.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.2.1.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.2.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.6.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.4.1.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.5.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.4.1.bn3.bias', 'model.backbone.conv_encoder.model.blocks.1.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.3.1.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.4.1.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.2.1.bn2.bias', 'model.backbone.conv_encoder.model.blocks.4.2.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.0.0.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.5.1.bn3.weight', 'model.backbone.conv_encoder.model.blocks.1.1.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.4.1.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.1.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.3.2.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.3.0.bn2.weight', 'model.backbone.conv_encoder.model.blocks.4.2.bn1.bias', 'model.backbone.conv_encoder.model.blocks.5.3.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.6.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.4.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.4.0.bn3.weight', 'model.backbone.conv_encoder.model.blocks.5.2.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.3.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.3.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.5.2.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.2.1.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.6.0.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.2.1.bn3.bias', 'model.backbone.conv_encoder.model.blocks.3.1.bn1.weight', 'model.backbone.conv_encoder.model.blocks.4.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.4.2.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.1.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn2.bias', 'model.backbone.conv_encoder.model.blocks.5.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.2.0.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.2.1.bn1.weight', 'model.backbone.conv_encoder.model.blocks.3.2.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.4.0.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.5.3.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.3.2.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.3.2.bn1.weight', 'model.backbone.conv_encoder.model.blocks.1.1.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.0.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.3.1.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.2.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.5.3.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.4.1.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.3.0.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.4.2.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.1.0.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.3.2.bn3.weight', 'model.backbone.conv_encoder.model.blocks.3.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.0.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.5.3.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.4.0.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.4.2.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.5.3.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.3.1.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.5.2.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.4.1.bn1.bias', 'model.backbone.conv_encoder.model.blocks.3.1.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.4.0.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.5.1.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.1.1.bn3.weight', 'model.backbone.conv_encoder.model.blocks.1.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.2.conv_pw.weight', 'model.backbone.conv_encoder.model.blocks.2.0.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.1.1.bn3.bias', 'model.backbone.conv_encoder.model.blocks.5.3.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.3.1.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.1.1.bn2.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.4.1.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.4.1.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.5.3.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.5.1.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.1.1.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.2.0.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.3.1.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.0.0.bn1.weight', 'model.backbone.conv_encoder.model.blocks.5.0.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.0.0.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.5.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.0.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.4.1.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.6.0.se.conv_reduce.weight', 'model.backbone.conv_encoder.model.blocks.5.2.bn3.bias', 'model.backbone.conv_encoder.model.blocks.5.1.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.5.3.bn1.bias', 'model.backbone.conv_encoder.model.blocks.2.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.2.0.bn2.bias', 'model.backbone.conv_encoder.model.blocks.3.2.bn1.bias', 'model.backbone.conv_encoder.model.blocks.3.2.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.4.0.bn3.bias', 'model.backbone.conv_encoder.model.blocks.2.0.bn3.bias', 'model.backbone.conv_encoder.model.blocks.4.2.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.3.0.se.conv_reduce.bias', 'model.backbone.conv_encoder.model.blocks.3.1.bn3.bias', 'model.backbone.conv_encoder.model.blocks.4.2.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.1.1.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.6.0.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.1.0.bn3.weight', 'model.backbone.conv_encoder.model.blocks.1.0.bn3.running_var', 'model.backbone.conv_encoder.model.blocks.5.2.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.3.0.bn3.bias', 'model.backbone.conv_encoder.model.blocks.4.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.6.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.2.1.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.3.1.se.conv_expand.bias', 'model.backbone.conv_encoder.model.conv_stem.weight', 'model.backbone.conv_encoder.model.blocks.5.2.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.3.1.bn2.bias', 'model.backbone.conv_encoder.model.blocks.4.2.bn3.weight', 'model.backbone.conv_encoder.model.blocks.5.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.1.1.bn2.bias', 'model.backbone.conv_encoder.model.blocks.5.1.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.4.1.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.1.1.bn1.weight', 'model.backbone.conv_encoder.model.blocks.6.0.bn1.bias', 'model.backbone.conv_encoder.model.blocks.4.2.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.5.2.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.3.2.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.6.0.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.5.1.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.2.1.bn2.running_var', 'model.backbone.conv_encoder.model.blocks.5.3.bn2.weight', 'model.backbone.conv_encoder.model.blocks.3.0.bn3.running_mean', 'model.backbone.conv_encoder.model.blocks.5.3.bn3.weight', 'model.backbone.conv_encoder.model.blocks.4.0.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.5.1.bn1.running_var', 'model.backbone.conv_encoder.model.blocks.1.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.3.0.bn2.running_mean', 'model.backbone.conv_encoder.model.blocks.2.1.conv_dw.weight', 'model.backbone.conv_encoder.model.blocks.5.0.se.conv_expand.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn3.bias', 'model.backbone.conv_encoder.model.blocks.1.1.conv_pwl.weight', 'model.backbone.conv_encoder.model.blocks.0.0.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.5.2.bn3.weight', 'model.backbone.conv_encoder.model.blocks.6.0.bn3.weight', 'model.backbone.conv_encoder.model.blocks.4.1.se.conv_expand.bias', 'model.backbone.conv_encoder.model.blocks.3.0.bn3.weight', 'model.backbone.conv_encoder.model.blocks.5.1.bn1.running_mean', 'model.backbone.conv_encoder.model.blocks.4.0.bn2.running_mean']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- model.backbone.conv_encoder.model.bn1.weight: found shape torch.Size([64]) in the checkpoint and torch.Size([32]) in the model instantiated\n",
      "- model.backbone.conv_encoder.model.bn1.bias: found shape torch.Size([64]) in the checkpoint and torch.Size([32]) in the model instantiated\n",
      "- model.backbone.conv_encoder.model.bn1.running_mean: found shape torch.Size([64]) in the checkpoint and torch.Size([32]) in the model instantiated\n",
      "- model.backbone.conv_encoder.model.bn1.running_var: found shape torch.Size([64]) in the checkpoint and torch.Size([32]) in the model instantiated\n",
      "- model.input_projection.weight: found shape torch.Size([256, 2048, 1, 1]) in the checkpoint and torch.Size([64, 320, 1, 1]) in the model instantiated\n",
      "- model.input_projection.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.query_position_embeddings.weight: found shape torch.Size([100, 256]) in the checkpoint and torch.Size([25, 64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.k_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.v_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.q_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.q_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.out_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn.out_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.self_attn_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.fc1.weight: found shape torch.Size([2048, 256]) in the checkpoint and torch.Size([2048, 64]) in the model instantiated\n",
      "- model.encoder.layers.0.fc2.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([64, 2048]) in the model instantiated\n",
      "- model.encoder.layers.0.fc2.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.final_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.0.final_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.k_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.v_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.q_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.q_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.out_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn.out_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.self_attn_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.fc1.weight: found shape torch.Size([2048, 256]) in the checkpoint and torch.Size([2048, 64]) in the model instantiated\n",
      "- model.encoder.layers.1.fc2.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([64, 2048]) in the model instantiated\n",
      "- model.encoder.layers.1.fc2.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.final_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.encoder.layers.1.final_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.k_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.k_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.v_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.v_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.q_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.q_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.out_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn.out_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.self_attn_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.k_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.k_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.v_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.v_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.q_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.q_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.out_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn.out_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.encoder_attn_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.fc1.weight: found shape torch.Size([2048, 256]) in the checkpoint and torch.Size([2048, 64]) in the model instantiated\n",
      "- model.decoder.layers.0.fc2.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([64, 2048]) in the model instantiated\n",
      "- model.decoder.layers.0.fc2.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.final_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.0.final_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.k_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.k_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.v_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.v_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.q_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.q_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.out_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn.out_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.self_attn_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.k_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.k_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.v_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.v_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.q_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.q_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.out_proj.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn.out_proj.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.encoder_attn_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.fc1.weight: found shape torch.Size([2048, 256]) in the checkpoint and torch.Size([2048, 64]) in the model instantiated\n",
      "- model.decoder.layers.1.fc2.weight: found shape torch.Size([256, 2048]) in the checkpoint and torch.Size([64, 2048]) in the model instantiated\n",
      "- model.decoder.layers.1.fc2.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.final_layer_norm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layers.1.final_layer_norm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layernorm.weight: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- model.decoder.layernorm.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([3, 64]) in the model instantiated\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- bbox_predictor.layers.0.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- bbox_predictor.layers.0.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- bbox_predictor.layers.1.weight: found shape torch.Size([256, 256]) in the checkpoint and torch.Size([64, 64]) in the model instantiated\n",
      "- bbox_predictor.layers.1.bias: found shape torch.Size([256]) in the checkpoint and torch.Size([64]) in the model instantiated\n",
      "- bbox_predictor.layers.2.weight: found shape torch.Size([4, 256]) in the checkpoint and torch.Size([4, 64]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:197: UserWarning: Attribute 'detr_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['detr_model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | detr_model | DetrForObjectDetection | 4.7 M \n",
      "------------------------------------------------------\n",
      "4.7 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.7 M     Total params\n",
      "18.980    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x000002535F295E40>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64db6a22ec73417f934486d2e47d274a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 16. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4715181804459aab28ccd0c5fdcbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea22d20bc7844f8b736887217d66114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:197: UserWarning: Attribute 'detr_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['detr_model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HyperParameters\n",
    "\n",
    "hyperparameters = itertools.product(*[\n",
    "    Config.BACKBONES,\n",
    "    Config.NUM_QUERIES,\n",
    "    Config.D_MODEL,\n",
    "    Config.TRANSFORMER_LAYERS,\n",
    "])\n",
    "\n",
    "hyperparameters = itertools.product(*[\n",
    "    ['efficientnet_b0.ra_in1k'],\n",
    "    [25],\n",
    "    [64],\n",
    "    [2],\n",
    "])\n",
    "\n",
    "\n",
    "# Hyperparameter Search\n",
    "\n",
    "for backbone, num_queries, d_model, transformer_layers in hyperparameters:\n",
    "    print('(Num Queries, Dim model, Enc-Dec Layers): ', \n",
    "            f'({num_queries}, {d_model}, {transformer_layers})' )\n",
    "\n",
    "    # Model Construction\n",
    "\n",
    "    config = DetrConfig.from_pretrained(\n",
    "        Config.CHECKPOINT,\n",
    "        num_labels=2,\n",
    "        id2label = {0:'Mass', 1: 'No-Mass'}, \n",
    "        label2id = {'Mass': 0, 'No-Mass': 1},\n",
    "        num_queries = num_queries,\n",
    "        d_model = d_model,\n",
    "        num_head = 8,\n",
    "        encoder_layers = transformer_layers,\n",
    "        decoder_layers = transformer_layers,\n",
    "        position_embedding_type  = 'sine',\n",
    "        decoder_ffn_dim = 2048,\n",
    "        encoder_ffn_dim = 2048,\n",
    "        backbone=backbone\n",
    "    )\n",
    "\n",
    "    model_name = [\n",
    "        f'backbone={backbone.split(\".\")[0]}',\n",
    "        f'queries={num_queries}',\n",
    "        f'dmodel={d_model}',\n",
    "        f'layers={transformer_layers}'\n",
    "    ]\n",
    "    \n",
    "    logs_dir = 'lightning_logs'\n",
    "    model_name = '_'.join(model_name)\n",
    "    \n",
    "    metrics_by_fold = []\n",
    "\n",
    "    # K-fold Cross Validation \n",
    "\n",
    "    for fold in range(1,11):\n",
    "        print(f\"Fold {fold}\")\n",
    "        \n",
    "        # Model\n",
    "        \n",
    "        detr_model = DetrForObjectDetection.from_pretrained(\n",
    "            Config.CHECKPOINT,\n",
    "            config = config,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "        model = DETRModel(detr_model=detr_model)\n",
    "        \n",
    "        # Datasets\n",
    "        \n",
    "        fold_dir = os.path.join(Config.DATASET, f'fold_{fold}')\n",
    "        \n",
    "        train_dataset = InBreastDataset(\n",
    "            images_path = os.path.join(fold_dir, 'train'),\n",
    "            processor=detr_processor\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            dataset = train_dataset,\n",
    "            batch_size = Config.BATCH_SIZE,\n",
    "            collate_fn = collate_fn,\n",
    "        )\n",
    "\n",
    "        valid_dataset = InBreastDataset(\n",
    "            images_path = os.path.join(fold_dir, 'valid'),\n",
    "            processor=detr_processor\n",
    "        )\n",
    "\n",
    "        valid_loader = DataLoader(\n",
    "            dataset = valid_dataset,\n",
    "            batch_size = Config.BATCH_SIZE,\n",
    "            collate_fn = collate_fn,\n",
    "        )\n",
    "        \n",
    "        # Training\n",
    "\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            save_top_k = 1,\n",
    "            save_last = True,\n",
    "            monitor = \"valid_loss\",\n",
    "            mode = \"min\"\n",
    "        )\n",
    "\n",
    "        early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "            monitor = 'valid_loss',\n",
    "            patience = 15\n",
    "        )\n",
    "\n",
    "        version = os.path.join(model_name, f'fold_{fold}')\n",
    "\n",
    "        logger = pl.loggers.TensorBoardLogger(\n",
    "            save_dir = './',\n",
    "            version = version\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            # max_epochs = Config.EPOCHS, \n",
    "            max_epochs = 1,\n",
    "            log_every_n_steps = 5, \n",
    "            callbacks = [\n",
    "                checkpoint_callback, \n",
    "                early_stopping_callback\n",
    "            ],\n",
    "            accelerator = Config.ACCELERATOR,\n",
    "            logger = logger\n",
    "        )\n",
    "        \n",
    "        trainer.fit(\n",
    "            model, \n",
    "            train_dataloaders = train_loader, \n",
    "            val_dataloaders = valid_loader\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Evaluation\n",
    "        \n",
    "        checkpoints_dir = os.path.join(logs_dir, version, 'checkpoints')\n",
    "        best_checkpoint = [f for f in os.listdir(checkpoints_dir) if 'last' not in f][0]\n",
    "        checkpoint_path = os.path.join(checkpoints_dir, best_checkpoint)\n",
    "        \n",
    "        model = DETRModel.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "        evaluator = CocoEvaluator(\n",
    "            coco_gt=valid_dataset.coco, \n",
    "            iou_types=[\"bbox\"]\n",
    "        )\n",
    "        \n",
    "        for batch in valid_loader:\n",
    "            outputs = model(batch['pixel_values'])\n",
    "            predictions = detr_processor.post_process_object_detection(outputs, threshold=0.1)\n",
    "            image_ids = [label['image_id'].item() for label in batch['labels']]\n",
    "            predictions = {image_id:output for image_id, output in zip(image_ids, predictions)}\n",
    "            predictions = prepare_for_coco_detection(predictions)\n",
    "            evaluator.update(predictions)\n",
    "            \n",
    "        evaluator.synchronize_between_processes()\n",
    "        evaluator.accumulate()\n",
    "        \n",
    "        # Metrics\n",
    "        \n",
    "        metrics_buffer = StringIO()\n",
    "        sys.stdout = metrics_buffer\n",
    "        evaluator.summarize()\n",
    "        sys.stdout = STDOUT\n",
    "        \n",
    "        metrics = metrics_buffer.getvalue()\n",
    "        metrics = metrics.split('\\n')\n",
    "        metrics = [m for m in metrics if 'Average' in m]\n",
    "        metrics_dict = {}\n",
    "        for metric in metrics:\n",
    "            name, value = metric.split(' = ')\n",
    "            metrics_dict[name[1:]] = float(value)\n",
    "        \n",
    "        metrics_by_fold.append(metrics_dict)\n",
    "        \n",
    "        shutil.rmtree(checkpoints_dir)\n",
    "          \n",
    "\n",
    "        # break # Fold\n",
    "    \n",
    "    # Aggregate Metrics\n",
    "    \n",
    "    index = [f'fold {fold}' for fold in range(1,11)]\n",
    "    metrics_by_fold = pd.DataFrame(metrics_by_fold, index=index)\n",
    "    metrics_by_fold.loc['mean'] = metrics_by_fold.mean()\n",
    "    \n",
    "    metrics_path = os.path.join(logs_dir, model_name, 'metrics.csv')\n",
    "    metrics_by_fold.to_csv(metrics_path)\n",
    "    \n",
    "    # break # Hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
