{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from coco_eval import CocoEvaluator\n",
    "from detr_config import Config\n",
    "from detr_dataset import InBreastDataset, collate_fn\n",
    "from detr_detection import prepare_for_coco_detection\n",
    "from detr_model import DETRModel\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (DeformableDetrConfig,\n",
    "                          DeformableDetrForObjectDetection,\n",
    "                          DeformableDetrImageProcessor, DetrConfig,\n",
    "                          DetrForObjectDetection, DetrImageProcessor)\n",
    "\n",
    "STDOUT = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- MODEL -------- \n",
      "ARCHITECTURE:  DETR \n",
      "BACKBONE:  resnet50 \n",
      "NUM QUERIES:  100 \n",
      "DIM MODEL:  256 \n",
      "ENC-DEC LAYERS:  6 \n",
      "------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HyperParameters\n",
    "\n",
    "hyperparameters = itertools.product(*[\n",
    "    Config.ARCHITECTURES,\n",
    "    Config.BACKBONES,\n",
    "    Config.NUM_QUERIES,\n",
    "    Config.D_MODEL,\n",
    "    Config.TRANSFORMER_LAYERS,\n",
    "])\n",
    "\n",
    "hyperparameters = [\n",
    "    ('DETR', 'resnet50', 100, 256, 6),\n",
    "    # ('D-DETR', 'resnet50', 300, 256, 6),\n",
    "]\n",
    "\n",
    "# Hyperparameter Search\n",
    "\n",
    "for architecture, backbone, num_queries, d_model, transformer_layers in hyperparameters:\n",
    "    \n",
    "    print('\\n-------- MODEL --------',\n",
    "          '\\nARCHITECTURE: ', architecture,\n",
    "          '\\nBACKBONE: ', backbone,\n",
    "          '\\nNUM QUERIES: ', num_queries,\n",
    "          '\\nDIM MODEL: ', d_model,\n",
    "          '\\nENC-DEC LAYERS: ', transformer_layers,\n",
    "          '\\n------------------------\\n')\n",
    "    \n",
    "    if architecture == 'DETR':\n",
    "        IMG_PROCESSOR_CLASS = DetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DetrConfig\n",
    "        DETR_CLASS = DetrForObjectDetection\n",
    "    else:\n",
    "        IMG_PROCESSOR_CLASS = DeformableDetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DeformableDetrConfig\n",
    "        DETR_CLASS = DeformableDetrForObjectDetection\n",
    "        \n",
    "    \n",
    "    image_processor = IMG_PROCESSOR_CLASS(\n",
    "        do_rescale = True,\n",
    "        size = {\"shortest_edge\": 800, \"longest_edge\": 800})\n",
    "    \n",
    "    \n",
    "    # Model Configuration\n",
    "\n",
    "    config = DETR_CONFIG_CLASS(\n",
    "        num_labels = Config.NUM_CLASSES,\n",
    "        # id2label = {0:'Mass', 1: 'No-Mass'}, \n",
    "        # label2id = {'Mass': 0, 'No-Mass': 1},\n",
    "        id2label = {0:'Mass'}, \n",
    "        label2id = {'Mass': 0},\n",
    "        num_queries = num_queries,\n",
    "        d_model = d_model,\n",
    "        num_head = 8,\n",
    "        encoder_layers = transformer_layers,\n",
    "        decoder_layers = transformer_layers,\n",
    "        backbone=backbone\n",
    "    )\n",
    "    \n",
    "    # Model Directory\n",
    "\n",
    "    model_name = [\n",
    "        f'balloons',\n",
    "        f'model={architecture}',\n",
    "        f'backbone={backbone.split(\".\")[0]}',\n",
    "        f'queries={num_queries}',\n",
    "        f'dmodel={d_model}',\n",
    "        f'layers={transformer_layers}'\n",
    "    ]\n",
    "    \n",
    "    model_name = '_'.join(model_name)\n",
    "    \n",
    "    model_dir = os.path.join(Config.LOGS_DIR, model_name)\n",
    "    # if os.path.exists(model_dir):\n",
    "    #     shutil.rmtree(model_dir)\n",
    "    \n",
    "    metrics_by_fold = []\n",
    "    index = []\n",
    "\n",
    "    # K-fold Cross Validation \n",
    "\n",
    "    for fold in range(1,11):\n",
    "        \n",
    "        # Model\n",
    "        \n",
    "        detr_model = DETR_CLASS(\n",
    "            config = config,\n",
    "        )\n",
    "\n",
    "        model = DETRModel(detr_model=detr_model)\n",
    "        \n",
    "        # Datasets\n",
    "        \n",
    "        fold_name = f'fold_{fold}'\n",
    "        \n",
    "        fold_dir = 'balloon'\n",
    "        \n",
    "        train_dataset = InBreastDataset(\n",
    "            images_path = os.path.join(fold_dir, 'train'),\n",
    "            processor=image_processor\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            dataset = train_dataset,\n",
    "            batch_size = Config.BATCH_SIZE,\n",
    "            collate_fn = collate_fn,\n",
    "        )\n",
    "\n",
    "        valid_dataset = InBreastDataset(\n",
    "            images_path = os.path.join(fold_dir, 'val'),\n",
    "            processor=image_processor\n",
    "        )\n",
    "\n",
    "        valid_loader = DataLoader(\n",
    "            dataset = valid_dataset,\n",
    "            batch_size = Config.BATCH_SIZE,\n",
    "            collate_fn = collate_fn,\n",
    "        )\n",
    "        \n",
    "        # Training\n",
    "\n",
    "        checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "            save_top_k = 1,\n",
    "            save_last = True,\n",
    "            monitor = \"valid_loss\",\n",
    "            mode = \"min\"\n",
    "        )\n",
    "\n",
    "        early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "            monitor = 'valid_loss',\n",
    "            patience = 20\n",
    "        )\n",
    "\n",
    "        version = os.path.join(model_name, fold_name)\n",
    "\n",
    "        logger = pl.loggers.TensorBoardLogger(\n",
    "            save_dir = './',\n",
    "            version = version\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs = Config.EPOCHS,\n",
    "            log_every_n_steps = 5, \n",
    "            callbacks = [\n",
    "                checkpoint_callback, \n",
    "                early_stopping_callback\n",
    "            ],\n",
    "            accelerator = Config.ACCELERATOR,\n",
    "            logger = logger\n",
    "        )\n",
    "        break\n",
    "        \n",
    "        # trainer.fit(\n",
    "        #     model, \n",
    "        #     train_dataloaders = train_loader, \n",
    "        #     val_dataloaders = valid_loader\n",
    "        # )\n",
    "        \n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        checkpoints_dir = os.path.join(Config.LOGS_DIR, version, 'checkpoints')\n",
    "        best_checkpoint = [f for f in os.listdir(checkpoints_dir) if 'last' not in f][0]\n",
    "        checkpoint_path = os.path.join(checkpoints_dir, best_checkpoint)\n",
    "        \n",
    "        model = DETRModel.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "        evaluator = CocoEvaluator(\n",
    "            coco_gt=valid_dataset.coco, \n",
    "            iou_types=[\"bbox\"]\n",
    "        )\n",
    "        \n",
    "        valid_predictions = False\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch in valid_loader:\n",
    "                outputs = model(batch['pixel_values'])\n",
    "                batch_size = outputs.logits.shape[0]\n",
    "                predictions = image_processor.post_process_object_detection(\n",
    "                    outputs, threshold=0.01, target_sizes=batch_size*[[800,800]])\n",
    "                image_ids = [label['image_id'].item() for label in batch['labels']]\n",
    "                predictions = {image_id:output for image_id, output in zip(image_ids, predictions)}\n",
    "                predictions = prepare_for_coco_detection(predictions)\n",
    "                if len(predictions) != 0:\n",
    "                    valid_predictions = True\n",
    "                    evaluator.update(predictions)\n",
    "            \n",
    "        if valid_predictions:\n",
    "            evaluator.synchronize_between_processes()\n",
    "            evaluator.accumulate()\n",
    "        \n",
    "            # Metrics\n",
    "            \n",
    "            metrics_buffer = StringIO()\n",
    "            sys.stdout = metrics_buffer\n",
    "            evaluator.summarize()\n",
    "            sys.stdout = STDOUT\n",
    "            \n",
    "            metrics = metrics_buffer.getvalue()\n",
    "            metrics = metrics.split('\\n')\n",
    "            metrics = [m for m in metrics if 'Average' in m]\n",
    "            metrics_dict = {}\n",
    "            for metric in metrics:\n",
    "                name, value = metric.split(' = ')\n",
    "                metrics_dict[name[1:]] = float(value)\n",
    "                \n",
    "        else:\n",
    "            metrics_dict = {\n",
    "                'Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ]': 0.0,\n",
    "                'Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ]': 0.0,\n",
    "                'Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ]': 0.0,\n",
    "                'Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ]': 0.0,\n",
    "                'Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ]': 0.0,\n",
    "                'Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ]': 0.0,\n",
    "                'Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ]': 0.0,\n",
    "                'Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ]': 0.0,\n",
    "                'Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ]': 0.0,\n",
    "                'Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ]': 0.0,\n",
    "                'Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ]': 0.0,\n",
    "                'Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ]': 0.0\n",
    "            }\n",
    "            \n",
    "            \n",
    "        metrics_by_fold.append(metrics_dict)\n",
    "        index.append(fold_name)\n",
    "        \n",
    "        if fold != 1:\n",
    "            print(\"Cleaning Checkpoints\")\n",
    "            # shutil.rmtree(checkpoints_dir)\n",
    "\n",
    "        break # Fold\n",
    "    \n",
    "    break\n",
    "    \n",
    "    # Aggregate Metrics\n",
    "    \n",
    "    metrics_by_fold = pd.DataFrame(metrics_by_fold, index=index)\n",
    "    metrics_by_fold.loc['mean'] = metrics_by_fold.mean()\n",
    "    \n",
    "    metrics_path = os.path.join(\n",
    "        Config.LOGS_DIR,\n",
    "        model_name, \n",
    "        Config.METRICS_FILE\n",
    "    )\n",
    "    \n",
    "    metrics_by_fold.to_csv(metrics_path)\n",
    "    \n",
    "    break # Hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 600, 800] at entry 0 and [3, 533, 799] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alejandro Duque\\Documents\\USFQ\\Proyecto Integrador\\Workspace\\DETR\\nb04_train_validate_DETR_balloons.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_balloons.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro Duque\\Documents\\USFQ\\Proyecto Integrador\\Workspace\\DETR\\detr_dataset.py:25\u001b[0m, in \u001b[0;36mcollate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcollate_fn\u001b[39m(batch):\n\u001b[1;32m---> 25\u001b[0m     pixel_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack([item[\u001b[39m0\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m item \u001b[39min\u001b[39;49;00m batch])\n\u001b[0;32m     26\u001b[0m     labels \u001b[39m=\u001b[39m [item[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch]\n\u001b[0;32m     27\u001b[0m     batch \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 600, 800] at entry 0 and [3, 533, 799] at entry 1"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
