{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from detr_config import Config\n",
    "from detr_dataset import get_dataset, get_dataloader\n",
    "from detr_trainer import get_trainer\n",
    "from detr_evaluation import load_best_model, get_metrics\n",
    "from detr_model import DETRModel\n",
    "from transformers import (DeformableDetrConfig,\n",
    "                          DeformableDetrForObjectDetection,\n",
    "                          DeformableDetrImageProcessor, DetrConfig,\n",
    "                          DetrForObjectDetection, DetrImageProcessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- MODEL --------\n",
      " balloon_v2_model=DETR_backbone=resnet50_queries=100_dmodel=256_layers=6 \n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DetrForObjectDetection:\n\tsize mismatch for class_labels_classifier.weight: copying a param with shape torch.Size([92, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).\n\tsize mismatch for class_labels_classifier.bias: copying a param with shape torch.Size([92]) from checkpoint, the shape in current model is torch.Size([2]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alejandro Duque\\Documents\\USFQ\\Proyecto Integrador\\Workspace\\DETR\\nb04_train_validate_DETR_copy.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m11\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m# Model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     image_processor \u001b[39m=\u001b[39m DetrImageProcessor\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mfacebook/detr-resnet-50\u001b[39m\u001b[39m\"\u001b[39m)        \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     detr_model \u001b[39m=\u001b[39m DetrForObjectDetection\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mfacebook/detr-resnet-50\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         num_labels \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         id2label \u001b[39m=\u001b[39;49m {\u001b[39m0\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39mMass\u001b[39;49m\u001b[39m'\u001b[39;49m}, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         label2id \u001b[39m=\u001b[39;49m {\u001b[39m'\u001b[39;49m\u001b[39mMass\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0\u001b[39;49m}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     model \u001b[39m=\u001b[39m DETRModel(detr_model\u001b[39m=\u001b[39mdetr_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W1sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39m# Datasets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\transformers\\modeling_utils.py:3091\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3081\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3082\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3084\u001b[0m     (\n\u001b[0;32m   3085\u001b[0m         model,\n\u001b[0;32m   3086\u001b[0m         missing_keys,\n\u001b[0;32m   3087\u001b[0m         unexpected_keys,\n\u001b[0;32m   3088\u001b[0m         mismatched_keys,\n\u001b[0;32m   3089\u001b[0m         offload_index,\n\u001b[0;32m   3090\u001b[0m         error_msgs,\n\u001b[1;32m-> 3091\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[0;32m   3092\u001b[0m         model,\n\u001b[0;32m   3093\u001b[0m         state_dict,\n\u001b[0;32m   3094\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3095\u001b[0m         resolved_archive_file,\n\u001b[0;32m   3096\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   3097\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[0;32m   3098\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[0;32m   3099\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[0;32m   3100\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[0;32m   3101\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[0;32m   3102\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[0;32m   3103\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[0;32m   3104\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[0;32m   3105\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(\u001b[39mgetattr\u001b[39;49m(model, \u001b[39m\"\u001b[39;49m\u001b[39mquantization_method\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m) \u001b[39m==\u001b[39;49m QuantizationMethod\u001b[39m.\u001b[39;49mBITS_AND_BYTES),\n\u001b[0;32m   3106\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[0;32m   3107\u001b[0m     )\n\u001b[0;32m   3109\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[0;32m   3110\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\transformers\\modeling_utils.py:3532\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msize mismatch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m error_msg:\n\u001b[0;32m   3529\u001b[0m         error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m   3530\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3531\u001b[0m         )\n\u001b[1;32m-> 3532\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00merror_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3534\u001b[0m \u001b[39mif\u001b[39;00m is_quantized:\n\u001b[0;32m   3535\u001b[0m     unexpected_keys \u001b[39m=\u001b[39m [elem \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m unexpected_keys \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mSCB\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m elem]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DetrForObjectDetection:\n\tsize mismatch for class_labels_classifier.weight: copying a param with shape torch.Size([92, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).\n\tsize mismatch for class_labels_classifier.bias: copying a param with shape torch.Size([92]) from checkpoint, the shape in current model is torch.Size([2]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "\n",
    "# HyperParameters\n",
    "\n",
    "hyperparameters = Config.HYPERPARAMS\n",
    "\n",
    "hyperparameters = [\n",
    "    ('DETR', 'resnet50', 100, 256, 6),\n",
    "    # ('D-DETR', 'resnet50', 300, 256, 6),\n",
    "]\n",
    "\n",
    "# Hyperparameter Search\n",
    "\n",
    "for architecture, backbone, num_queries, d_model, transformer_layers in hyperparameters:\n",
    "    \n",
    "    if architecture == 'DETR':\n",
    "        IMG_PROCESSOR_CLASS = DetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DetrConfig\n",
    "        DETR_CLASS = DetrForObjectDetection\n",
    "    else:\n",
    "        IMG_PROCESSOR_CLASS = DeformableDetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DeformableDetrConfig\n",
    "        DETR_CLASS = DeformableDetrForObjectDetection    \n",
    "    \n",
    "    # Model Configuration\n",
    "\n",
    "    config = DETR_CONFIG_CLASS(\n",
    "        num_labels = Config.NUM_CLASSES,\n",
    "        id2label = {0:'Mass'}, \n",
    "        label2id = {'Mass': 0},\n",
    "        num_queries = num_queries,\n",
    "        d_model = d_model,\n",
    "        encoder_layers = transformer_layers,\n",
    "        decoder_layers = transformer_layers,\n",
    "        backbone=backbone\n",
    "    )\n",
    "    \n",
    "    # Model Directory\n",
    "\n",
    "    model_name = [\n",
    "        'balloon_v2', # Remove this\n",
    "        f'model={architecture}',\n",
    "        f'backbone={backbone.split(\".\")[0]}',\n",
    "        f'queries={num_queries}',\n",
    "        f'dmodel={d_model}',\n",
    "        f'layers={transformer_layers}'\n",
    "    ]\n",
    "    \n",
    "    model_name = '_'.join(model_name)\n",
    "    model_dir = os.path.join(Config.LOGS_DIR, model_name)\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    print('\\n-------- MODEL --------\\n', model_name,\n",
    "          '\\n-----------------------\\n')\n",
    "    \n",
    "    \n",
    "    # K-fold Cross Validation \n",
    "    \n",
    "    metrics_by_fold = []\n",
    "    index = []\n",
    "\n",
    "    for fold in range(1,11):\n",
    "        \n",
    "        # Model\n",
    "        \n",
    "        image_processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")        \n",
    "        detr_model = DetrForObjectDetection.from_pretrained(\n",
    "            \"facebook/detr-resnet-50\",\n",
    "            num_labels = 1,\n",
    "            id2label = {0:'Mass'}, \n",
    "            label2id = {'Mass': 0}\n",
    "        )\n",
    "        model = DETRModel(detr_model=detr_model)\n",
    "        \n",
    "        # Datasets\n",
    "        \n",
    "        fold_name = f'fold_{fold}'\n",
    "        dataset_dir = os.path.join(Config.DATASET, fold_name)\n",
    "        dataset_dir = './balloon/' # Remove this\n",
    "        \n",
    "        train_dir = os.path.join(dataset_dir, 'train')\n",
    "        train_dataset = get_dataset(train_dir, image_processor)\n",
    "        train_loader = get_dataloader(train_dataset, image_processor)\n",
    "        \n",
    "        valid_dir = os.path.join(dataset_dir, 'valid')\n",
    "        valid_dataset = get_dataset(valid_dir, image_processor)\n",
    "        valid_loader = get_dataloader(valid_dataset, image_processor)\n",
    "\n",
    "        # Training\n",
    "        \n",
    "        version = os.path.join(model_name, fold_name)\n",
    "        trainer = get_trainer(version)\n",
    "        break\n",
    "        trainer.fit(model, train_dataloaders=train_loader,\n",
    "                    val_dataloaders=valid_loader)\n",
    "        \n",
    "        # Validation\n",
    "\n",
    "        model = load_best_model(version)\n",
    "        metrics_dict = get_metrics(model, valid_dataset, image_processor, threshold=0.001)\n",
    "        metrics_by_fold.append(metrics_dict)\n",
    "        index.append(fold_name)\n",
    "        \n",
    "        if fold != 1:\n",
    "            print(\"Cleaning Checkpoints\")\n",
    "            # shutil.rmtree(checkpoints_dir)\n",
    "\n",
    "        break # Fold\n",
    "    \n",
    "    \n",
    "    # Aggregate Metrics\n",
    "    \n",
    "    metrics_by_fold = pd.DataFrame(metrics_by_fold, index=index)\n",
    "    metrics_by_fold.loc['mean'] = metrics_by_fold.mean()\n",
    "    metrics_path = os.path.join(Config.LOGS_DIR, model_name, Config.METRICS_FILE)\n",
    "    metrics_by_fold.to_csv(metrics_path)\n",
    "    \n",
    "    break # Hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- MODEL --------\n",
      " balloon_model=DETR_backbone=resnet50_queries=100_dmodel=256_layers=6 \n",
      "-----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:197: UserWarning: Attribute 'detr_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['detr_model'])`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name       | Type                   | Params\n",
      "------------------------------------------------------\n",
      "0 | detr_model | DetrForObjectDetection | 41.5 M\n",
      "------------------------------------------------------\n",
      "41.3 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.5 M    Total params\n",
      "166.007   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.named_parameters at 0x000001C01190F940>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\detr-env\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'lightning_logs\\\\balloon_model=DETR_backbone=resnet50_queries=100_dmodel=256_layers=6\\\\fold_1\\\\checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alejandro Duque\\Documents\\USFQ\\Proyecto Integrador\\Workspace\\DETR\\nb04_train_validate_DETR_copy.ipynb Cell 3\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W3sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, train_dataloaders\u001b[39m=\u001b[39mtrain_loader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W3sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m             val_dataloaders\u001b[39m=\u001b[39mvalid_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W3sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39m# Validation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W3sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m model \u001b[39m=\u001b[39m load_best_model(version)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W3sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m metrics_dict \u001b[39m=\u001b[39m get_metrics(model, valid_dataset, image_processor, threshold\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro%20Duque/Documents/USFQ/Proyecto%20Integrador/Workspace/DETR/nb04_train_validate_DETR_copy.ipynb#W3sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m metrics_by_fold\u001b[39m.\u001b[39mappend(metrics_dict)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro Duque\\Documents\\USFQ\\Proyecto Integrador\\Workspace\\DETR\\detr_evaluation.py:18\u001b[0m, in \u001b[0;36mload_best_model\u001b[1;34m(version)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_best_model\u001b[39m(version):\n\u001b[0;32m     17\u001b[0m     checkpoints_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(Config\u001b[39m.\u001b[39mLOGS_DIR, version, \u001b[39m'\u001b[39m\u001b[39mcheckpoints\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m     best_checkpoint \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(checkpoints_dir) \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlast\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m f][\u001b[39m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m     checkpoint_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(checkpoints_dir, best_checkpoint)\n\u001b[0;32m     20\u001b[0m     model \u001b[39m=\u001b[39m DETRModel\u001b[39m.\u001b[39mload_from_checkpoint(\n\u001b[0;32m     21\u001b[0m         checkpoint_path \u001b[39m=\u001b[39m checkpoint_path,\n\u001b[0;32m     22\u001b[0m         map_location \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(Config\u001b[39m.\u001b[39mDEVICE)\n\u001b[0;32m     23\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'lightning_logs\\\\balloon_model=DETR_backbone=resnet50_queries=100_dmodel=256_layers=6\\\\fold_1\\\\checkpoints'"
     ]
    }
   ],
   "source": [
    "\n",
    "# HyperParameters\n",
    "\n",
    "hyperparameters = Config.HYPERPARAMS\n",
    "\n",
    "hyperparameters = [\n",
    "    ('DETR', 'resnet50', 100, 256, 6),\n",
    "    # ('D-DETR', 'resnet50', 300, 256, 6),\n",
    "]\n",
    "\n",
    "# Hyperparameter Search\n",
    "\n",
    "for architecture, backbone, num_queries, d_model, transformer_layers in hyperparameters:\n",
    "    \n",
    "    if architecture == 'DETR':\n",
    "        IMG_PROCESSOR_CLASS = DetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DetrConfig\n",
    "        DETR_CLASS = DetrForObjectDetection\n",
    "    else:\n",
    "        IMG_PROCESSOR_CLASS = DeformableDetrImageProcessor\n",
    "        DETR_CONFIG_CLASS = DeformableDetrConfig\n",
    "        DETR_CLASS = DeformableDetrForObjectDetection    \n",
    "    \n",
    "    # Model Configuration\n",
    "\n",
    "    config = DETR_CONFIG_CLASS(\n",
    "        num_labels = Config.NUM_CLASSES,\n",
    "        id2label = {0:'Mass'}, \n",
    "        label2id = {'Mass': 0},\n",
    "        num_queries = num_queries,\n",
    "        d_model = d_model,\n",
    "        encoder_layers = transformer_layers,\n",
    "        decoder_layers = transformer_layers,\n",
    "        backbone=backbone\n",
    "    )\n",
    "    \n",
    "    # Model Directory\n",
    "\n",
    "    model_name = [\n",
    "        # 'balloon', # Remove this\n",
    "        # f'model={architecture}',\n",
    "        # f'backbone={backbone.split(\".\")[0]}',\n",
    "        # f'queries={num_queries}',\n",
    "        # f'dmodel={d_model}',\n",
    "        # f'layers={transformer_layers}'\n",
    "        f'Original-DETR'\n",
    "    ]\n",
    "    \n",
    "    model_name = '_'.join(model_name)\n",
    "    model_dir = os.path.join(Config.LOGS_DIR, model_name)\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    print('\\n-------- MODEL --------\\n', model_name,\n",
    "          '\\n-----------------------\\n')\n",
    "    \n",
    "    \n",
    "    # K-fold Cross Validation \n",
    "    \n",
    "    metrics_by_fold = []\n",
    "    index = []\n",
    "\n",
    "    for fold in range(1,11):\n",
    "        \n",
    "        # Model\n",
    "        \n",
    "        image_processor = IMG_PROCESSOR_CLASS()        \n",
    "        detr_model = DETR_CLASS(config=config)\n",
    "        model = DETRModel(detr_model=detr_model)\n",
    "        \n",
    "        # Datasets\n",
    "        \n",
    "        fold_name = f'fold_{fold}'\n",
    "        dataset_dir = os.path.join(Config.DATASET, fold_name)\n",
    "        # dataset_dir = './balloon/' # Remove this\n",
    "        \n",
    "        train_dir = os.path.join(dataset_dir, 'train')\n",
    "        train_dataset = get_dataset(train_dir, image_processor)\n",
    "        train_loader = get_dataloader(train_dataset, image_processor)\n",
    "        \n",
    "        valid_dir = os.path.join(dataset_dir, 'valid')\n",
    "        valid_dataset = get_dataset(valid_dir, image_processor)\n",
    "        valid_loader = get_dataloader(valid_dataset, image_processor)\n",
    "\n",
    "        # Training\n",
    "        \n",
    "        version = os.path.join(model_name, fold_name)\n",
    "        trainer = get_trainer(version)\n",
    "        trainer.fit(model, train_dataloaders=train_loader,\n",
    "                    val_dataloaders=valid_loader)\n",
    "        \n",
    "        # Validation\n",
    "\n",
    "        model = load_best_model(version)\n",
    "        metrics_dict = get_metrics(model, valid_dataset, image_processor, threshold=0.001)\n",
    "        metrics_by_fold.append(metrics_dict)\n",
    "        index.append(fold_name)\n",
    "        \n",
    "        if fold != 1:\n",
    "            print(\"Cleaning Checkpoints\")\n",
    "            # shutil.rmtree(checkpoints_dir)\n",
    "\n",
    "        # break # Fold\n",
    "    \n",
    "    \n",
    "    # Aggregate Metrics\n",
    "    \n",
    "    metrics_by_fold = pd.DataFrame(metrics_by_fold, index=index)\n",
    "    metrics_by_fold.loc['mean'] = metrics_by_fold.mean()\n",
    "    metrics_path = os.path.join(Config.LOGS_DIR, model_name, Config.METRICS_FILE)\n",
    "    metrics_by_fold.to_csv(metrics_path)\n",
    "    \n",
    "    break # Hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
